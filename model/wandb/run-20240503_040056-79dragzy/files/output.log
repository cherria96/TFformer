[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
/home/user126/anaconda3/envs/dt_idl/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:396: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
  | Name                | Type                | Params
------------------------------------------------------------
0 | decomposition       | SeriesDecomposition | 0
1 | embedding_layer     | Linear              | 64
2 | positional_encoding | PositionalEncoding  | 0
3 | transformer_encoder | ModuleList          | 19.4 K
4 | linear1             | Sequential          | 545
5 | linear2             | Sequential          | 4.2 K
6 | output_dropout      | Dropout             | 0
7 | loss_fn             | MSELoss             | 0
------------------------------------------------------------
24.2 K    Trainable params
0         Non-trainable params
24.2 K    Total params
0.097     Total estimated model params size (MB)
/home/user126/anaconda3/envs/dt_idl/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]{"Attention": "type", "DataLoader": "type", "ExponentialMovingAverage": "type", "F": "module", "LayerNorm": "type", "LightningModule": "type", "MultiHeadedAttention": "type", "PositionalEncoding": "type", "PositionwiseFeedForward": "type", "SeriesDecomposition": "type", "TFformer": "type", "TimeSeriesDataset": "type", "TransformerEncoderBlock": "type", "VariableSelection": "type", "WandbLogger": "ABCMeta", "basic_block_cls": "type", "batch": "dict", "batch_size": "int", "block": "TransformerEncoderBlock", "causal_mask": "Tensor", "data": "ndarray", "dim_C": "int", "dim_O": "int", "dim_T": "int", "dropout_rate": "float", "embedded": "Tensor", "epochs": "int", "gc": "module", "get_ipython": "function", "head_size": "int", "iw": "int", "logger": "Logger", "logging": "module", "math": "module", "model": "TFformer", "nn": "module", "np": "module", "num_heads": "int", "num_layer": "int", "optim": "module", "os": "module", "ow": "int", "pdb": "module", "pl": "module", "positional_encoding": "PositionalEncoding", "samples": "int", "seq_hidden_units": "int", "stride": "int", "sys": "module", "test_data": "TimeSeriesDataset", "test_dataloader": "DataLoader", "torch": "module", "train_data": "TimeSeriesDataset", "train_dataloader": "DataLoader", "trainer": "Trainer", "transformer_encoder": "ModuleList", "val_data": "TimeSeriesDataset", "val_dataloader": "DataLoader", "wandb": "module", "wandb_logger": "WandbLogger"}
{"Attention": "type", "DataLoader": "type", "ExponentialMovingAverage": "type", "F": "module", "LayerNorm": "type", "LightningModule": "type", "MultiHeadedAttention": "type", "PositionalEncoding": "type", "PositionwiseFeedForward": "type", "SeriesDecomposition": "type", "TFformer": "type", "TimeSeriesDataset": "type", "TransformerEncoderBlock": "type", "VariableSelection": "type", "WandbLogger": "ABCMeta", "basic_block_cls": "type", "batch": "dict", "batch_size": "int", "block": "TransformerEncoderBlock", "causal_mask": "Tensor", "data": "ndarray", "dim_C": "int", "dim_O": "int", "dim_T": "int", "dropout_rate": "float", "embedded": "Tensor", "epochs": "int", "gc": "module", "get_ipython": "function", "head_size": "int", "iw": "int", "logger": "Logger", "logging": "module", "math": "module", "model": "TFformer", "nn": "module", "np": "module", "num_heads": "int", "num_layer": "int", "optim": "module", "os": "module", "ow": "int", "pdb": "module", "pl": "module", "positional_encoding": "PositionalEncoding", "samples": "int", "seq_hidden_units": "int", "stride": "int", "sys": "module", "test_data": "TimeSeriesDataset", "test_dataloader": "DataLoader", "torch": "module", "train_data": "TimeSeriesDataset", "train_dataloader": "DataLoader", "trainer": "Trainer", "transformer_encoder": "ModuleList", "val_data": "TimeSeriesDataset", "val_dataloader": "DataLoader", "wandb": "module", "wandb_logger": "WandbLogger"}
{"Attention": "type", "DataLoader": "type", "ExponentialMovingAverage": "type", "F": "module", "LayerNorm": "type", "LightningModule": "type", "MultiHeadedAttention": "type", "PositionalEncoding": "type", "PositionwiseFeedForward": "type", "SeriesDecomposition": "type", "TFformer": "type", "TimeSeriesDataset": "type", "TransformerEncoderBlock": "type", "VariableSelection": "type", "WandbLogger": "ABCMeta", "basic_block_cls": "type", "batch": "dict", "batch_size": "int", "block": "TransformerEncoderBlock", "causal_mask": "Tensor", "data": "ndarray", "dim_C": "int", "dim_O": "int", "dim_T": "int", "dropout_rate": "float", "embedded": "Tensor", "epochs": "int", "gc": "module", "get_ipython": "function", "head_size": "int", "iw": "int", "logger": "Logger", "logging": "module", "math": "module", "model": "TFformer", "nn": "module", "np": "module", "num_heads": "int", "num_layer": "int", "optim": "module", "os": "module", "ow": "int", "pdb": "module", "pl": "module", "positional_encoding": "PositionalEncoding", "samples": "int", "seq_hidden_units": "int", "stride": "int", "sys": "module", "test_data": "TimeSeriesDataset", "test_dataloader": "DataLoader", "torch": "module", "train_data": "TimeSeriesDataset", "train_dataloader": "DataLoader", "trainer": "Trainer", "transformer_encoder": "ModuleList", "val_data": "TimeSeriesDataset", "val_dataloader": "DataLoader", "wandb": "module", "wandb_logger": "WandbLogger"}
{"Attention": "type", "DataLoader": "type", "ExponentialMovingAverage": "type", "F": "module", "LayerNorm": "type", "LightningModule": "type", "MultiHeadedAttention": "type", "PositionalEncoding": "type", "PositionwiseFeedForward": "type", "SeriesDecomposition": "type", "TFformer": "type", "TimeSeriesDataset": "type", "TransformerEncoderBlock": "type", "VariableSelection": "type", "WandbLogger": "ABCMeta", "basic_block_cls": "type", "batch": "dict", "batch_size": "int", "block": "TransformerEncoderBlock", "causal_mask": "Tensor", "data": "ndarray", "dim_C": "int", "dim_O": "int", "dim_T": "int", "dropout_rate": "float", "embedded": "Tensor", "epochs": "int", "gc": "module", "get_ipython": "function", "head_size": "int", "iw": "int", "logger": "Logger", "logging": "module", "math": "module", "model": "TFformer", "nn": "module", "np": "module", "num_heads": "int", "num_layer": "int", "optim": "module", "os": "module", "ow": "int", "pdb": "module", "pl": "module", "positional_encoding": "PositionalEncoding", "samples": "int", "seq_hidden_units": "int", "stride": "int", "sys": "module", "test_data": "TimeSeriesDataset", "test_dataloader": "DataLoader", "torch": "module", "train_data": "TimeSeriesDataset", "train_dataloader": "DataLoader", "trainer": "Trainer", "transformer_encoder": "ModuleList", "val_data": "TimeSeriesDataset", "val_dataloader": "DataLoader", "wandb": "module", "wandb_logger": "WandbLogger"}
/home/user126/anaconda3/envs/dt_idl/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2157: UserWarning: Run (v5q3ec2b) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.
  lambda data: self._console_raw_callback("stdout", data),