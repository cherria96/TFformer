  | Name                       | Type                       | Params
--------------------------------------------------------------------------
0 | A_input_transformation     | Linear                     | 80
1 | X_input_transformation     | Linear                     | 16
2 | Y_input_transformation     | Linear                     | 32
3 | V_input_transformation     | Linear                     | 32
4 | self_positional_encoding_k | RelativePositionalEncoding | 248
5 | self_positional_encoding_v | RelativePositionalEncoding | 248
6 | transformer_blocks         | ModuleList                 | 8.2 K
7 | output_dropout             | Dropout                    | 0
--------------------------------------------------------------------------
8.4 K     Trainable params
0         Non-trainable params
8.4 K     Total params
0.033     Total estimated model params size (MB)
/home/user126/anaconda3/envs/dt_idl/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
/home/user126/anaconda3/envs/dt_idl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))














































































































































































































