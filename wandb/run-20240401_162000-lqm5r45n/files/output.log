  | Name                       | Type                       | Params
--------------------------------------------------------------------------
0 | A_input_transformation     | Linear                     | 80
1 | X_input_transformation     | Linear                     | 16
2 | Y_input_transformation     | Linear                     | 32
3 | V_input_transformation     | Linear                     | 32
4 | self_positional_encoding_k | RelativePositionalEncoding | 248
5 | self_positional_encoding_v | RelativePositionalEncoding | 248
6 | transformer_blocks         | ModuleList                 | 8.2 K
7 | output_dropout             | Dropout                    | 0
--------------------------------------------------------------------------
8.4 K     Trainable params
0         Non-trainable params
8.4 K     Total params
0.033     Total estimated model params size (MB)
/home/user126/anaconda3/envs/dt_idl/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
Epoch 0:   0%|                                                                                                                             | 0/40 [00:00<?, ?it/s]
/home/user126/anaconda3/envs/dt_idl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
















































































































































































































































Epoch 49:  80%|███████████████████████████████████████████████████████████████████████████████████████▏                     | 32/40 [00:07<00:01,  4.27it/s, v_num=r45n]
`Trainer.fit` stopped: `max_epochs=50` reached.
/home/user126/anaconda3/envs/dt_idl/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
/home/user126/TFformer/model/CT_ourmodel.py:345: UserWarning: Using a target size (torch.Size([256, 59, 1])) that is different to the input size (torch.Size([256, 59, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
Epoch 49: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:09<00:00,  4.35it/s, v_num=r45n]
Testing DataLoader 0:  50%|███████████████████████████████████████████████████████▌                                                       | 2/4 [00:00<00:00, 13.41it/s]
/home/user126/TFformer/model/CT_ourmodel.py:345: UserWarning: Using a target size (torch.Size([232, 59, 1])) that is different to the input size (torch.Size([232, 59, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse_loss = nn.functional.mse_loss(outcome_pred, batch['outputs'], reduce=False)
INFO:model.CT_ourmodel:RMSE calculation for val.
INFO:model.CT_ourmodel:Predictions for val.
/home/user126/anaconda3/envs/dt_idl/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
INFO:__main__:Val normalised RMSE (all): 45.80285891345648; Val normalised RMSE (orig): 45.61327093677791
INFO:model.CT_ourmodel:RMSE calculation for test.
Testing DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 12.99it/s]
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
      test_mse_loss          5.676955703802555
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Predicting DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 13.04it/s]


Predicting DataLoader 0:  87%|███████████████████████████████████████████████████████████████████████████████████████████▋              | 77/89 [00:05<00:00, 13.64it/s]
Predicting DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 89/89 [00:06<00:00, 13.66it/s]
{'encoder_val_rmse_all': 45.80285891345648, 'encoder_val_rmse_orig': 45.61327093677791, 'encoder_test_rmse_all': 72.13135112385865, 'encoder_test_rmse_orig': 61.1835068464533, 'encoder_test_rmse_last': 62.18616461487101}